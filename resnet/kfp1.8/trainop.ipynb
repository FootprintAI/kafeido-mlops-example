{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Training Operation for ResNet on CIFAR-10 (PyTorch)\n",
    "\n",
    "This notebook contains the PyTorch training logic that will be embedded into the KFP pipeline.\n",
    "\n",
    "## Workflow\n",
    "1. Edit and test your training code in this notebook\n",
    "2. Build the pipeline using `./build.sh` (reads directly from this notebook)\n",
    "3. Submit the generated `outputs/pipeline.yaml` to Vertex AI\n",
    "\n",
    "## Key Function\n",
    "The main `trainOp()` function is what gets embedded into the KFP component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trainop-function",
   "metadata": {},
   "outputs": [],
   "source": "def trainOp(\n    model_relative_path: str = 'model', \n    model_name: str = 'resnet_pytorch', \n    prefix: str = '1711140944', \n    epochs: int = 50, \n    networks: int = 3, \n    batch_size: int = 128,\n    classes_list: List[str] = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'],\n    model_version: str = '@auto-timestamp',\n    deploy_to_watsonxai: bool = False,\n    kfp_output_path: str = None,  # KFP output path (for KFP 1.8 compatibility)\n):\n    \"\"\"Main training operation using PyTorch.\n    \n    This function serves as the main entry point for training.\n    It handles:\n    - Data loading from CIFAR-10\n    - Model training with ResNet architecture using PyTorch\n    - Model export in Triton-compatible format\n    - Supports both local runs and KFP artifact output\n    \n    Args:\n        model_relative_path: Relative path for model output (default: 'model')\n        model_name: Name of the model (default: 'resnet_pytorch')\n        prefix: Data prefix (legacy, not used for CIFAR-10)\n        epochs: Number of training epochs (default: 50)\n        networks: Number of residual blocks, determines depth (default: 3)\n        batch_size: Training batch size (default: 128)\n        classes_list: Class names for CIFAR-10\n        model_version: Model version number (default: '@auto-timestamp' - will be auto-generated by caller)\n        deploy_to_watsonxai: Whether to deploy to Watson X.ai (default: False)\n        kfp_output_path: KFP output path for artifact upload\n    \"\"\"\n    import os\n    import pathlib\n    import shutil\n    import json\n    import numpy as np\n    \n    import torch\n    import torch.nn as nn\n    import torch.optim as optim\n    import torchvision\n    import torchvision.transforms as transforms\n    from torch.utils.data import DataLoader\n    from PIL import Image\n    \n    home = '/home/jovyan'\n    \n    raw_data_dir = os.path.join(home, \"data\")\n    \n    # Use KFP output path if provided (for artifact output)\n    # Otherwise use local path (for local testing/runs)\n    if kfp_output_path:\n        output_model_dir = kfp_output_path\n        print(f\"Using KFP Output path: {output_model_dir}\")\n        print(\"Model will be saved as KFP artifact\")\n    else:\n        # Save model directly under model_relative_path, not model_relative_path/model_name\n        # Triton expects: /mnt/models/resnet_pytorch/, not /mnt/models/model/resnet_pytorch/\n        output_model_dir = os.path.join(home, model_relative_path)\n        print(f\"Using local path: {output_model_dir}\")\n    \n    print(\"PyTorch version:\", torch.__version__)\n    print(\"NumPy version:\", np.__version__)\n    print(\"Output directory:\", output_model_dir)\n    print(\"Model name:\", model_name)\n    print(\"Model version:\", model_version)\n    print(\"Classes:\", classes_list)\n    \n    pathlib.Path(raw_data_dir).mkdir(parents=True, exist_ok=True)\n    pathlib.Path(output_model_dir).mkdir(parents=True, exist_ok=True)\n    \n    # Device configuration\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n    \n    # ResNet Block for CIFAR-10\n    class BasicBlock(nn.Module):\n        expansion = 1\n        \n        def __init__(self, in_planes, planes, stride=1):\n            super(BasicBlock, self).__init__()\n            self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n            self.bn1 = nn.BatchNorm2d(planes)\n            self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n            self.bn2 = nn.BatchNorm2d(planes)\n            \n            self.shortcut = nn.Sequential()\n            if stride != 1 or in_planes != self.expansion * planes:\n                self.shortcut = nn.Sequential(\n                    nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n                    nn.BatchNorm2d(self.expansion * planes)\n                )\n        \n        def forward(self, x):\n            out = torch.relu(self.bn1(self.conv1(x)))\n            out = self.bn2(self.conv2(out))\n            out += self.shortcut(x)\n            out = torch.relu(out)\n            return out\n    \n    # ResNet Model\n    class ResNet(nn.Module):\n        def __init__(self, block, num_blocks, num_classes=10):\n            super(ResNet, self).__init__()\n            self.in_planes = 16\n            \n            self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n            self.bn1 = nn.BatchNorm2d(16)\n            self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n            self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n            self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n            self.linear = nn.Linear(64 * block.expansion, num_classes)\n        \n        def _make_layer(self, block, planes, num_blocks, stride):\n            strides = [stride] + [1] * (num_blocks - 1)\n            layers = []\n            for stride in strides:\n                layers.append(block(self.in_planes, planes, stride))\n                self.in_planes = planes * block.expansion\n            return nn.Sequential(*layers)\n        \n        def forward(self, x):\n            out = torch.relu(self.bn1(self.conv1(x)))\n            out = self.layer1(out)\n            out = self.layer2(out)\n            out = self.layer3(out)\n            # Use adaptive_avg_pool2d for TorchScript compatibility\n            out = torch.nn.functional.adaptive_avg_pool2d(out, (1, 1))\n            out = out.view(out.size(0), -1)\n            out = self.linear(out)\n            return out\n    \n    def ResNetCIFAR(num_blocks_per_layer, num_classes=10):\n        \"\"\"Create ResNet for CIFAR-10.\n        \n        Args:\n            num_blocks_per_layer: Number of blocks per layer (e.g., 3 for ResNet-20)\n            num_classes: Number of output classes\n        \"\"\"\n        return ResNet(BasicBlock, [num_blocks_per_layer] * 3, num_classes)\n    \n    # Data loading\n    print(\"Loading CIFAR-10 dataset...\")\n    \n    # Custom ToTensor that avoids NumPy compatibility issues\n    class PILToTensor:\n        \"\"\"Convert PIL Image to tensor without NumPy conversion.\"\"\"\n        def __call__(self, pic):\n            if not isinstance(pic, Image.Image):\n                raise TypeError(f'pic should be PIL Image. Got {type(pic)}')\n            \n            # Convert PIL Image to tensor manually\n            img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n            img = img.view(pic.size[1], pic.size[0], len(pic.getbands()))\n            # Put channels first and convert to float\n            img = img.permute((2, 0, 1)).contiguous()\n            return img.to(dtype=torch.float32).div(255)\n    \n    transform_train = transforms.Compose([\n        transforms.RandomCrop(32, padding=4),\n        transforms.RandomHorizontalFlip(),\n        PILToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n    \n    transform_test = transforms.Compose([\n        PILToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n    \n    trainset = torchvision.datasets.CIFAR10(\n        root=raw_data_dir, train=True, download=True, transform=transform_train\n    )\n    # Use num_workers=0 to avoid multiprocessing issues with custom transforms\n    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n    \n    testset = torchvision.datasets.CIFAR10(\n        root=raw_data_dir, train=False, download=True, transform=transform_test\n    )\n    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)\n    \n    print(f\"Training samples: {len(trainset)}\")\n    print(f\"Test samples: {len(testset)}\")\n    \n    # Model setup\n    n = int(networks)\n    depth = n * 6 + 2  # For CIFAR-10: n=3 -> ResNet-20\n    model_type = f'ResNet{depth}'\n    print(f\"Building model: {model_type}\")\n    \n    model = ResNetCIFAR(num_blocks_per_layer=n, num_classes=10)\n    model = model.to(device)\n    \n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[80, 120, 160, 180], gamma=0.1)\n    \n    # Training function\n    def train_epoch(epoch):\n        model.train()\n        train_loss = 0\n        correct = 0\n        total = 0\n        \n        for batch_idx, (inputs, targets) in enumerate(trainloader):\n            inputs, targets = inputs.to(device), targets.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n            \n            if batch_idx % 100 == 0:\n                print(f'Epoch: {epoch} [{batch_idx}/{len(trainloader)}] '\n                      f'Loss: {train_loss/(batch_idx+1):.3f} | '\n                      f'Acc: {100.*correct/total:.2f}% ({correct}/{total})')\n        \n        return train_loss / len(trainloader), 100. * correct / total\n    \n    # Testing function\n    def test_epoch(epoch):\n        model.eval()\n        test_loss = 0\n        correct = 0\n        total = 0\n        \n        with torch.no_grad():\n            for batch_idx, (inputs, targets) in enumerate(testloader):\n                inputs, targets = inputs.to(device), targets.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, targets)\n                \n                test_loss += loss.item()\n                _, predicted = outputs.max(1)\n                total += targets.size(0)\n                correct += predicted.eq(targets).sum().item()\n        \n        acc = 100. * correct / total\n        print(f'Test Epoch: {epoch} | Loss: {test_loss/len(testloader):.3f} | Acc: {acc:.2f}% ({correct}/{total})')\n        return test_loss / len(testloader), acc\n    \n    # Training loop\n    print(f\"\\nStarting training for {epochs} epochs...\")\n    best_acc = 0\n    \n    for epoch in range(epochs):\n        print(f\"\\n=== Epoch {epoch+1}/{epochs} ===\")\n        print(f\"Learning rate: {optimizer.param_groups[0]['lr']}\")\n        \n        train_loss, train_acc = train_epoch(epoch)\n        test_loss, test_acc = test_epoch(epoch)\n        scheduler.step()\n        \n        print(f\"epoch={epoch}\")\n        print(f\"Train-Accuracy={train_acc:.6f}\")\n        print(f\"Train-Loss={train_loss:.6f}\")\n        print(f\"Validation-Accuracy={test_acc:.6f}\")\n        print(f\"Validation-Loss={test_loss:.6f}\")\n        \n        # Save best model\n        if test_acc > best_acc:\n            best_acc = test_acc\n            print(f\"Saving best model (accuracy: {best_acc:.2f}%)...\")\n    \n    print(f\"\\nTraining complete! Best accuracy: {best_acc:.2f}%\")\n    \n    # Save model in Triton-compatible structure\n    # Triton structure: <model_repository>/<model_name>/<version>/model.pt\n    # where model_repository is output_model_dir\n    model_root = os.path.join(output_model_dir, model_name)\n    model_version_dir = os.path.join(model_root, model_version)\n    \n    # Clear existing version directory if it exists\n    if os.path.isdir(model_version_dir):\n        shutil.rmtree(model_version_dir)\n    \n    pathlib.Path(model_version_dir).mkdir(parents=True, exist_ok=True)\n    \n    # Save TorchScript model (Triton PyTorch backend requires TorchScript)\n    print(f\"\\nSaving model in Triton format...\")\n    model.eval()\n    example_input = torch.randn(1, 3, 32, 32).to(device)\n    traced_model = torch.jit.trace(model, example_input)\n    model_path = os.path.join(model_version_dir, 'model.pt')\n    traced_model.save(model_path)\n    print(f\"Model saved to: {model_path}\")\n    \n    # Create Triton config.pbtxt\n    config_content = f'''name: \"{model_name}\"\nplatform: \"pytorch_libtorch\"\nmax_batch_size: {batch_size}\n\ninput [\n  {{\n    name: \"INPUT__0\"\n    data_type: TYPE_FP32\n    dims: [ 3, 32, 32 ]\n  }}\n]\n\noutput [\n  {{\n    name: \"OUTPUT__0\"\n    data_type: TYPE_FP32\n    dims: [ 10 ]\n  }}\n]\n\nversion_policy: {{ all {{ }} }}\n'''\n    \n    config_path = os.path.join(model_root, 'config.pbtxt')\n    with open(config_path, 'w') as f:\n        f.write(config_content)\n    print(f\"Triton config saved to: {config_path}\")\n    \n    # Save labels.txt at model root (for Triton)\n    labels_path = os.path.join(model_root, 'labels.txt')\n    with open(labels_path, 'w') as f:\n        f.write('\\n'.join(classes_list))\n    print(f\"Labels saved to: {labels_path}\")\n    \n    # Save metadata.json for reference\n    metadata = {\n        'model_name': model_name,\n        'model_type': model_type,\n        'framework': 'pytorch',\n        'platform': 'pytorch_libtorch',\n        'num_classes': 10,\n        'input_shape': [3, 32, 32],\n        'epochs': epochs,\n        'best_accuracy': float(best_acc),\n        'classes': classes_list,\n        'version': model_version,\n    }\n    \n    metadata_path = os.path.join(model_root, 'metadata.json')\n    with open(metadata_path, 'w') as f:\n        json.dump(metadata, f, indent=2)\n    print(f\"Metadata saved to: {metadata_path}\")\n    \n    print(f\"\\nTriton model structure:\")\n    print(f\"  {model_root}/\")\n    print(f\"  ├── config.pbtxt\")\n    print(f\"  ├── labels.txt\")\n    print(f\"  ├── metadata.json\")\n    print(f\"  └── {model_version}/\")\n    print(f\"      └── model.pt\")\n    print(f\"\\nFull path: {output_model_dir}/{model_name}\")\n    \n    print(\"\\nDone!\")"
  },
  {
   "cell_type": "markdown",
   "id": "test-section",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Uncomment and run the cell below to test the trainOp function locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-trainop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test trainOp locally (uncomment to run)\n",
    "# trainOp(\n",
    "#     model_relative_path='model',\n",
    "#     model_name='resnet_pytorch',\n",
    "#     prefix='testprefix',\n",
    "#     epochs=2,  # Use 2 epochs for quick testing\n",
    "#     networks=3,  # ResNet-20\n",
    "#     batch_size=128,\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}